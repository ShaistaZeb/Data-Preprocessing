{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Te_IOB2.ipynb","provenance":[],"authorship_tag":"ABX9TyNFydaE4yBapLYmjnv4oP0A"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jmxySUrbGLF4"},"outputs":[],"source":["!pip install flair\n","!pip install translate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"y2EnZ2iGcdmd","outputId":"a62c1893-688e-4f66-d773-529b472437f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["2022-06-11 14:04:38,130 loading file /root/.flair/models/ner-english/4f4cdab26f24cb98b732b389e6cebc646c36f54cfd6e0b7d3b90b25656e4262f.8baa8ae8795f4df80b28e7f7b61d788ecbb057d1dc85aacb316f1bd02837a4a4\n","2022-06-11 14:04:40,452 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n"]},{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/translate/translate.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtext_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRANSLATION_API_MAX_LENGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprovider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_wraped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext_wraped\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/translate/providers/mymemory_translated.py\u001b[0m in \u001b[0;36mget_translation\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'matches'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mnext_best_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext_best_match\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'translation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mStopIteration\u001b[0m: ","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-1d21631a9dcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    182\u001b[0m              \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                  \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetTranslationFromIIITAPI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m#transliteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                  \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m#translation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m                  \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                      \u001b[0mtl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m     \u001b[0;31m#updating tl dictionary with tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-38-1d21631a9dcd>\u001b[0m in \u001b[0;36mtrans\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m                                        \u001b[0;31m#function translates english word to telugu word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtranslator\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mTranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_lang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"telugu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtranslation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/translate/translate.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtext_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRANSLATION_API_MAX_LENGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprovider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_wraped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext_wraped\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: generator raised StopIteration"]}],"source":["#to run this code first run the below to lines\n","#pip install flair\n","#pip install translate\n","\n","from flair.data import Sentence\n","from flair.models import SequenceTagger\n","import pandas as pd\n","from tqdm import tqdm\n","from difflib import SequenceMatcher\n","import re\n","import pickle\n","\n","import flair\n","from flair.data import Sentence\n","from flair.models import SequenceTagger\n","import requests\n","import json\n","from translate import Translator\n","\n","\n","def trans(word):                                        #function translates english word to telugu word\n","    translator= Translator(to_lang=\"telugu\")\n","    translation = translator.translate(word)\n","    return translation\n","\n","def te_stemmer(word):                                   # function will return a telugu word by trimming its ending\n","    \n","    if(word.endswith(\"ల\") == True or\n","      word.endswith(\"ఓ\") == True):\n","        return word[:len(word)-1]    \n","    \n","    if(word.endswith(\"డు\") == True or\n","        word.endswith(\"ము\") == True or\n","        word.endswith(\"వు\") == True or\n","        word.endswith(\"లు\") == True or\n","        word.endswith(\"ని\") == True or\n","        word.endswith(\"ను\") == True or\n","        word.endswith(\"చే\") == True or\n","        word.endswith(\"తో\") == True or\n","        word.endswith(\"కై\") == True or\n","        word.endswith(\"లో\") == True or\n","        word.endswith(\"కు\") == True or\n","        word.endswith(\"కి\") == True):\n","        return word[:len(word)-2]\n","    \n","    if(word.endswith(\"చేత\") == True or\n","        word.endswith(\"తోడ\") == True or\n","        word.endswith(\"వలన\") == True or\n","        word.endswith(\"ఓరీ\") == True or\n","        word.endswith(\"ఓయీ\") == True or\n","        word.endswith(\"ఓసీ\") == True):\n","        return word[:len(word)-3]\n","    \n","    if(word.endswith(\"లోపల\") == True or\n","        word.endswith(\"కంటె\") == True):\n","        return word[:len(word)-4]\n","    \n","    if(word.endswith(\"కొఱకు\") == True or\n","        word.endswith(\"కొరకు\") == True or\n","        word.endswith(\"పట్టి\") == True or\n","        word.endswith(\"యొక్క\") == True):\n","        return word[:len(word)-5]\n","    \n","    if(word.endswith(\"గూర్చి\") == True):\n","        return word[:len(word)-6]\n","       \n","    if(word.endswith(\"గురించి\") == True):\n","        return word[:len(word)-7]\n","    \n","    if(word.startswith(\"ఓ\") == True):\n","        return word[1:]\n","    \n","    if(word.startswith(\"ఓయీ\") == True or \n","      word.startswith(\"ఓరీ\") == True or\n","      word.startswith(\"ఓసీ\") == True):\n","        return word[3:]\n","    \n","    return word\n","\n","# This script to get the English to Telugu Translation\n","def GetTranslationFromIIITAPI(src):\n","    # response = requests.post(\"https://ssmt.iiit.ac.in/elil_iiith\", json = {\"text\":src, \"model\":\" \"})\n","    data = {\"text\":src, \"source_language\":\"eng\", \"target_language\":\"tel\"}\n","    response = requests.post(\"https://ssmt.iiit.ac.in/mt_linker\", data=json.dumps(data), headers={\"Content-Type\": \"application/json\",\n","    \"Accept\": \"*/*\"})\n","    model_translations = response.json()['data']\n","    return model_translations\n","\n","def matcher(string, pattern):\n","    '''\n","    Return the start and end index of any pattern present in the text.\n","    '''\n","    match_list = []\n","    pattern = pattern.strip()\n","    seqMatch = SequenceMatcher(None, string, pattern, autojunk=False)\n","    match = seqMatch.find_longest_match(0, len(string), 0, len(pattern))\n","    if (match.size == len(pattern)):\n","        start = match.a\n","        end = match.a + match.size\n","        match_tup = (start, end)\n","        string = string.replace(pattern, \"X\" * len(pattern), 1)\n","        match_list.append(match_tup)\n","        \n","    return match_list, string\n","\n","def mark_sentence(s, match_list):\n","    '''\n","    Marks all the entities in the sentence as per the BIO scheme. \n","    '''\n","    word_dict = {}\n","    for word in s.split():\n","        word_dict[word] = 'O'\n","        \n","    for start, end, e_type in match_list:\n","        temp_str = s[start:end]\n","        tmp_list = temp_str.split()\n","        if len(tmp_list) > 1:\n","            word_dict[tmp_list[0]] = 'B-' + e_type\n","            for w in tmp_list[1:]:\n","                word_dict[w] = 'I-' + e_type\n","        else:\n","            word_dict[temp_str] = 'B-' + e_type\n","    return word_dict\n","\n","f=open(r\"train_en.txt\",mode='r',encoding='utf-8')\n","text = f.read().splitlines()       #reading english dataset\n","t=open(r\"train_te.txt\",mode='r')\n","textt= t.read().splitlines()       #reading same telugu dataset\n","tl={}\n","for i in range(len(textt)):   \n","    for word in textt[i].split():         #removing extra characters from telugu words\n","         x = word.replace(\"\\u200c\",\"\")\n","         x = word.replace(\",\",\"\")\n","         x = word.replace(\":\",\"\")\n","         x = word.replace(\";\",\"\")\n","         x = word.replace(\"`\",\"\")\n","         tl[x] = '0'               #appending to dictionary          \n","my = [*range(1, len(text), 1)]\n","dic = list(zip(my,text,textt))  \n","df = pd.DataFrame(dic,columns=['ind','sent','tsent']) #creating a dataframe with 3 columns index, eng sentences, corresponding telugu sentences\n","d = {} \n","tagger = SequenceTagger.load('ner')  #tagging PER, LOC, ORG, MISC\n","main_list=[]\n","for text in df['sent']:\n","  sentence = Sentence(text)\n","  tagger.predict(sentence)\n","  l=[]\n","  l.append(text)\n","  l1=[]\n","  for entity in sentence.get_spans('ner'):\n","    r = entity.text,entity.get_label(\"ner\").value\n","    l1.append((entity.text,entity.get_label(\"ner\").value))\n","  l.append(l1)\n","  main_list.append(l)                #sentence and its tagged words are appended\n","data = pd.DataFrame(main_list, columns=['text', 'annotation'])    #making dataframe\n","with open('new.txt' , 'w') as fr:     #file to store output   \n","      temp = []\n","      for annot in data.annotation: \n","          if annot == []:\n","             temp.append([])\n","          else: \n","             til = []  \n","             for i in range(len(annot)):         #tagging in IOB2 format\n","                 e_type = annot[i][1]\n","                 temp_list = annot[i][0].split() \n","                 if len(temp_list) > 1:\n","                    til.append((temp_list[0],'B-' + e_type))\n","                    for w in temp_list[1:]:\n","                        til.append((w,'I-' + e_type))       \n","                 else:\n","                    til.append((temp_list[0],'B-' + e_type))\n","             temp.append(til)                        \n","      df['tags'] = temp   #adding new column to existing dataframe df('ind','sent','tsent')\n","      for i in range(df.shape[0]):\n","          if df.tags[i] == []:\n","             i = i + 1  #incrementing on getting a empty english tagged word set\n","          else:\n","             temp = df.tsent[i].split()  #splitting telugu sentence for performing stemming, translation and transliteration\n","             p = []\n","             for k in temp:\n","                p.append(te_stemmer(k))   #stemming\n","             for j in range(len(df.tags[i])):\n","                 x = GetTranslationFromIIITAPI(df.tags[i][j][0])    #transliteration\n","                 y = trans(df.tags[i][j][0])     #translation\n","                 if x in temp: \n","                     tl[x] = df.tags[i][j][1]     #updating tl dictionary with tags\n","                 if y in temp:    \n","                     tl[y] = df.tags[i][j][1]                 \n","      for key in tl.keys():\n","          fr.writelines(key + ' ' + tl[key] +'\\n')     #writing output to new.txt file\n","      fr.writelines('\\n')"]}]}